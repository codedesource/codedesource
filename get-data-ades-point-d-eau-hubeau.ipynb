{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubeau_get_stations_ades(numéro_département: int) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer la liste (fichier CSV) des points d'eau d'un département et la retourner sous forme d'un DataFrame.\n",
    "    Exemple de requête :\n",
    "    https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/stations.csv?code_departement=66&size=200\n",
    "    \"\"\"\n",
    "    url = 'https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/stations.csv'\n",
    "    grand_nombre_magique = 9999\n",
    "    query_params = {'code_departement': numéro_département, 'size': grand_nombre_magique}\n",
    "    response = requests.get(url, params=query_params, )\n",
    "    df_liste_stations = pd.read_csv(io.BytesIO(response.content), sep=';')\n",
    "    return df_liste_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroniques_station(infos_station: dict) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer les données d'intérêt sur le code BSS d'une station.\n",
    "    Exemple de requête :\n",
    "    https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/chroniques.csv?code_bss=10908X0136/DUCUP2&size=20000\n",
    "    \"\"\"\n",
    "    url = 'https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/chroniques.csv'\n",
    "    # grand_nombre_magique = 20000\n",
    "    query_params = {\n",
    "        'code_bss': infos_station.get('code_bss'), 'size': infos_station.get('nb_mesures_piezo')}\n",
    "    response = requests.get(url, params=query_params)\n",
    "    if response.headers.get('Content-Length') == 0 \\\n",
    "            or 'Content-Encoding' not in response.headers:\n",
    "        return None\n",
    "    df = pd.read_csv(io.BytesIO(response.content), sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubeau_get_chroniques_des_stations(df_liste_stations: pd.DataFrame, nom_fichier_destination: str) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer, pour chaque station de la liste, les données d'intérêt et les sauvegarder itérativement dans un fichier CSV\n",
    "    \"\"\"\n",
    "    infos_stations_liste = df_liste_stations.to_dict(orient='records')\n",
    "    garder_lentête = True\n",
    "    with open(nom_fichier_destination, 'w', newline='\\n') as fichier_csv_cible:\n",
    "        fichier_csv_cible.write('')\n",
    "    with tqdm(total=len(infos_stations_liste), ncols=100) as progr_bar:\n",
    "        for infos_station in infos_stations_liste[:]:\n",
    "            progr_bar.set_description(f\"Station {infos_station.get('code_bss')}\")\n",
    "            df_chroniques_station = get_chroniques_station(infos_station)\n",
    "            progr_bar.update()\n",
    "            if df_chroniques_station is None:\n",
    "                continue\n",
    "            df_tmp = pd.merge(left=pd.DataFrame([infos_station]),\n",
    "                              right=df_chroniques_station,\n",
    "                              on=['code_bss', 'urn_bss'], how='outer')\n",
    "            df_tmp.to_csv(nom_fichier_destination, mode='a',\n",
    "                          sep=';', index=False, header=garder_lentête)\n",
    "            garder_lentête = False\n",
    "    return pd.read_csv(nom_fichier_destination, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numéro_département = 66\n",
    "nom_fichier_destination = f'hubeau_chroniques_des_stations_ades_dans_{numéro_département}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 86 stations dans le département 66.\n",
      "Il y a 83 stations pour lesquelles il existe au moins une mesure enregistrée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Station 10915X0395/PZ: 100%|████████████████████████████████████████| 83/83 [02:54<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "df_liste_stations = hubeau_get_stations_ades(numéro_département)\n",
    "print(f\"Il y a {len(df_liste_stations)} stations dans le département {numéro_département}.\")\n",
    "df_liste_stations_avec_mesures = df_liste_stations[df_liste_stations['nb_mesures_piezo'] > 0]\n",
    "print(f\"Il y a {len(df_liste_stations_avec_mesures)} stations pour lesquelles il existe au moins une mesure enregistrée.\")\n",
    "df_infos_stations_et_chroniques = hubeau_get_chroniques_des_stations(df_liste_stations_avec_mesures, nom_fichier_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_infos_stations_et_chroniques = pd.read_csv(nom_fichier_destination, sep=';', low_memory=False)\n",
    "colonnes_dans_lordre = ['code_bss', 'date_debut_mesure', 'date_fin_mesure',\n",
    "                        'code_commune_insee', 'nom_commune', 'x', 'y', 'codes_bdlisa',\n",
    "                        'bss_id', 'altitude_station', 'nb_mesures_piezo',\n",
    "                        'code_departement', 'nom_departement', 'libelle_pe',\n",
    "                        'profondeur_investigation', 'codes_masse_eau_edl', 'noms_masse_eau_edl',\n",
    "                        'date_maj', 'date_mesure', 'timestamp_mesure',\n",
    "                        'niveau_nappe_eau', 'mode_obtention', 'statut', 'qualification',\n",
    "                        'code_continuite', 'nom_continuite', 'code_producteur',\n",
    "                        'nom_producteur', 'code_nature_mesure', 'nom_nature_mesure',\n",
    "                        'profondeur_nappe', 'urn_bss', 'urns_bdlisa', 'urns_masse_eau_edl']\n",
    "df_infos_stations_et_chroniques = df_infos_stations_et_chroniques[colonnes_dans_lordre]\n",
    "colonnes_renommées = {'x': 'longitude_x', 'y': 'latitude_y'}\n",
    "df_infos_stations_et_chroniques.rename(columns=colonnes_renommées, inplace=True)\n",
    "niveau_min = df_infos_stations_et_chroniques['niveau_nappe_eau'].min()\n",
    "niveau_max = df_infos_stations_et_chroniques['niveau_nappe_eau'].max()\n",
    "calcul_IPS = lambda x: (x['niveau_nappe_eau'] - niveau_min) / (niveau_max - niveau_min)\n",
    "df_infos_stations_et_chroniques['indicateur_piezometrique_standardise'] = df_infos_stations_et_chroniques.apply(calcul_IPS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos_stations_et_chroniques.to_csv(nom_fichier_destination, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valider le fichier CSV produit en comptant le nombre de champs de chaque ligne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_sep = ';'\n",
    "header = ''\n",
    "how_many_fields_in_header = 0\n",
    "with open(nom_fichier_destination, 'r') as fichier_csv_cible:\n",
    "    for i, line in enumerate(fichier_csv_cible, start=1):\n",
    "        if i == 1:\n",
    "            header = line\n",
    "            how_many_fields_in_header = line.count(field_sep)\n",
    "        if line.count(field_sep) != how_many_fields_in_header:\n",
    "            print(str(i).zfill(10), ':', header)\n",
    "            print(str(i).zfill(10), ':', line)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
