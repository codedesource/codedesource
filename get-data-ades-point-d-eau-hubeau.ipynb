{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubeau_get_stations_ades(numéro_département: int) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer la liste (fichier CSV) des points d'eau d'un département et la retourner sous forme d'un DataFrame. Exemple de requête :\n",
    "    \n",
    "    https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/stations.csv?code_departement=66&size=200\n",
    "    \"\"\"\n",
    "    url = 'https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/stations.csv'\n",
    "    grand_nombre_magique = 9999\n",
    "    query_params = {'code_departement': numéro_département, 'size': grand_nombre_magique}\n",
    "    response = requests.get(url, params=query_params, )\n",
    "    df_liste_stations = pd.read_csv(io.BytesIO(response.content), sep=';')\n",
    "    return df_liste_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroniques_station(infos_station: dict) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer les données d'intérêt sur le code BSS d'une station. Exemple de requête :\n",
    "    \n",
    "    https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/chroniques.csv?code_bss=10908X0136/DUCUP2&size=20000\n",
    "    \"\"\"\n",
    "    url = 'https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/chroniques.csv'\n",
    "    query_params = {\n",
    "        'code_bss': infos_station.get('code_bss'), 'size': infos_station.get('nb_mesures_piezo')}\n",
    "    response = requests.get(url, params=query_params)\n",
    "    if response.headers.get('Content-Length') == 0 \\\n",
    "            or 'Content-Encoding' not in response.headers:\n",
    "        return None\n",
    "    df = pd.read_csv(io.BytesIO(response.content), sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_référentiel_IPS(liste_indicateurs_toute_la_période: list) -> dict:\n",
    "    \"\"\"Retourne un dictionnaire composé de couples {libellé: intervalle de valeurs IPS}, \n",
    "    autrement dit {\"un libellé\": [valeur inf., valeur sup.]} :\n",
    "    \n",
    "    {\n",
    "    'Niveaux très bas':             [0, 0.14285714285714285],\n",
    "    'Niveaux bas':                  [0.14295714285714284, 0.2857142857142857],\n",
    "    'Niveaux modérément bas':       [0.2858142857142857, 0.42857142857142855],\n",
    "    'Niveaux autour de la moyenne': [0.42867142857142854, 0.5714285714285714],\n",
    "    'Niveaux modérément hauts':     [0.5715285714285714, 0.7142857142857142],\n",
    "    'Niveaux hauts':                [0.7143857142857142, 0.8571428571428571],\n",
    "    'Niveaux très hauts':           [0.8572428571428571, 1.0]\n",
    "    }\n",
    "    \n",
    "    D'après la documentation :\n",
    "    - https://ades.eaufrance.fr/Spip?p=IMG/pdf/index_piezo_final.pdf#page=2\n",
    "    - http://infoterre.brgm.fr/rapports/RP-61807-FR.pdf#page=80\n",
    "    \"\"\"\n",
    "    ips_min = min(liste_indicateurs_toute_la_période)\n",
    "    ips_max = max(liste_indicateurs_toute_la_période)\n",
    "    ips_valeurs = np.linspace(ips_min, ips_max, 7 + 1)\n",
    "    ips_libellés = ['très bas', 'bas', 'modérément bas', 'autour de la moyenne', 'modérément hauts', 'hauts', 'très hauts']\n",
    "    ips_référentiel = {}\n",
    "    petit_décalage = 0\n",
    "    for i, (lib, val) in enumerate(zip(ips_libellés, ips_valeurs[1:])):\n",
    "        if i == 0:\n",
    "            val_inf, val_sup = [0, val]\n",
    "        else:\n",
    "            val_inf, val_sup = [ips_valeurs[i] + petit_décalage, val]\n",
    "        ips_référentiel |= {'Niveaux ' + lib: [val_inf, val_sup]}\n",
    "    return ips_référentiel    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def déterminer_libellé_IPS(indicateur: float, ips_référentiel: dict) -> str:\n",
    "    \"\"\"Détermine le libellé pour un indicateur IPS donné en entrée.\n",
    "    \n",
    "    D'après la documentation :\n",
    "    - https://ades.eaufrance.fr/Spip?p=IMG/pdf/index_piezo_final.pdf#page=2\n",
    "    - http://infoterre.brgm.fr/rapports/RP-61807-FR.pdf#page=80\n",
    "    \"\"\"\n",
    "    if np.isnan(indicateur):\n",
    "        return ''\n",
    "    for libellé, (val_inf, val_sup) in ips_référentiel.items():\n",
    "        if indicateur == 0 and val_inf == 0:\n",
    "            return libellé\n",
    "        if val_inf < indicateur <= val_sup:\n",
    "            return libellé\n",
    "    raise ValueError(f'Valeur {indicateur} ne rentre dans aucun des intervalles de notre référentiel IPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubeau_get_chroniques_des_stations(df_liste_stations: pd.DataFrame, nom_fichier_destination: str) -> pd.DataFrame:\n",
    "    \"\"\"Récupérer, pour chaque station de la liste, les données d'intérêt et les sauvegarder itérativement dans un fichier CSV\n",
    "    \"\"\"\n",
    "    infos_stations_liste = df_liste_stations.to_dict(orient='records')\n",
    "    garder_lentête = True\n",
    "    with open(nom_fichier_destination, 'w', newline='\\n') as fichier_csv_cible:\n",
    "        fichier_csv_cible.write('')\n",
    "    with tqdm(total=len(infos_stations_liste), ncols=100) as progr_bar:\n",
    "        for infos_station in infos_stations_liste[:]:\n",
    "            progr_bar.set_description(f\"Station {infos_station.get('code_bss')}\")\n",
    "            df_chroniques_station = get_chroniques_station(infos_station)\n",
    "            progr_bar.update()\n",
    "            if df_chroniques_station is None:\n",
    "                continue\n",
    "            df_tmp = pd.merge(left=pd.DataFrame([infos_station]),\n",
    "                              right=df_chroniques_station,\n",
    "                              on=['code_bss', 'urn_bss'], how='outer')\n",
    "            niveau_min = df_tmp['niveau_nappe_eau'].min()\n",
    "            niveau_max = df_tmp['niveau_nappe_eau'].max()\n",
    "            calcul_IPS = lambda x: pd.NA if np.isnan(x['niveau_nappe_eau']) else (x['niveau_nappe_eau'] - niveau_min) / (niveau_max - niveau_min)\n",
    "            df_tmp['indicateur_piezometrique_standardise'] = df_tmp.apply(calcul_IPS, axis=1)\n",
    "            liste_indicateurs_toute_la_période = df_tmp['indicateur_piezometrique_standardise'].to_list()\n",
    "            ips_référentiel = get_référentiel_IPS(liste_indicateurs_toute_la_période)\n",
    "            df_tmp['libelle_indicateur_piezometrique_standardise'] = df_tmp['indicateur_piezometrique_standardise'].apply(lambda x: déterminer_libellé_IPS(x, ips_référentiel))\n",
    "            df_tmp.to_csv(nom_fichier_destination, mode='a',\n",
    "                          sep=';', index=False, header=garder_lentête)\n",
    "            garder_lentête = False\n",
    "    return pd.read_csv(nom_fichier_destination, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "numéro_département = 66\n",
    "nom_fichier_destination = f'hubeau_chroniques_des_stations_ades_dans_{numéro_département}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 86 stations dans le département 66.\n",
      "Il y a 83 stations pour lesquelles il existe au moins une mesure enregistrée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Station 10984X0003/AIGUAN:  66%|███████████████████████▊            | 55/83 [01:57<00:36,  1.32s/it]C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_12544\\2618744094.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  calcul_IPS = lambda x: pd.NA if np.isnan(x['niveau_nappe_eau']) else (x['niveau_nappe_eau'] - niveau_min) / (niveau_max - niveau_min)\n",
      "Station 10915X0395/PZ: 100%|████████████████████████████████████████| 83/83 [02:42<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "df_liste_stations = hubeau_get_stations_ades(numéro_département)\n",
    "print(f\"Il y a {len(df_liste_stations)} stations dans le département {numéro_département}.\")\n",
    "df_liste_stations_avec_mesures = df_liste_stations[df_liste_stations['nb_mesures_piezo'] > 0]\n",
    "print(f\"Il y a {len(df_liste_stations_avec_mesures)} stations pour lesquelles il existe au moins une mesure enregistrée.\")\n",
    "df_infos_stations_et_chroniques = hubeau_get_chroniques_des_stations(df_liste_stations_avec_mesures, nom_fichier_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos_stations_et_chroniques = pd.read_csv(nom_fichier_destination, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_dans_lordre = ['code_bss', 'date_debut_mesure', 'date_fin_mesure',\n",
    "                        'code_commune_insee', 'nom_commune', 'x', 'y', 'codes_bdlisa',\n",
    "                        'bss_id', 'altitude_station', 'nb_mesures_piezo',\n",
    "                        'code_departement', 'nom_departement', 'libelle_pe',\n",
    "                        'profondeur_investigation', 'codes_masse_eau_edl', 'noms_masse_eau_edl',\n",
    "                        'date_maj', 'date_mesure', 'timestamp_mesure',\n",
    "                        'niveau_nappe_eau', 'mode_obtention', 'statut', 'qualification',\n",
    "                        'code_continuite', 'nom_continuite', 'code_producteur',\n",
    "                        'nom_producteur', 'code_nature_mesure', 'nom_nature_mesure',\n",
    "                        'profondeur_nappe', 'indicateur_piezometrique_standardise', \n",
    "                        'libelle_indicateur_piezometrique_standardise',\n",
    "                        'urn_bss', 'urns_bdlisa', 'urns_masse_eau_edl']\n",
    "df_infos_stations_et_chroniques = df_infos_stations_et_chroniques[colonnes_dans_lordre]\n",
    "#\n",
    "colonnes_renommées = {'x': 'longitude_x', 'y': 'latitude_y'}\n",
    "df_infos_stations_et_chroniques.rename(columns=colonnes_renommées, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "libelle_indicateur_piezometrique_standardise\n",
       "Niveaux bas                     65325\n",
       "Niveaux autour de la moyenne    60851\n",
       "Niveaux très bas                58089\n",
       "Niveaux modérément bas          55686\n",
       "Niveaux modérément hauts        55024\n",
       "Niveaux hauts                   45388\n",
       "Niveaux très hauts              17540\n",
       "NaN                               719\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infos_stations_et_chroniques['libelle_indicateur_piezometrique_standardise'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos_stations_et_chroniques.to_csv(nom_fichier_destination, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valider le fichier CSV produit en comptant le nombre de champs de chaque ligne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_sep = ';'\n",
    "header = ''\n",
    "how_many_fields_in_header = 0\n",
    "with open(nom_fichier_destination, 'r') as fichier_csv_cible:\n",
    "    for i, line in enumerate(fichier_csv_cible, start=1):\n",
    "        if i == 1:\n",
    "            header = line\n",
    "            how_many_fields_in_header = line.count(field_sep)\n",
    "        if line.count(field_sep) != how_many_fields_in_header:\n",
    "            print(str(i).zfill(10), ':', header)\n",
    "            print(str(i).zfill(10), ':', line)\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schéma types de données pour BigQuery :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_bss:string,\n",
      "date_debut_mesure:string,\n",
      "date_fin_mesure:string,\n",
      "code_commune_insee:int64,\n",
      "nom_commune:string,\n",
      "longitude_x:float64,\n",
      "latitude_y:float64,\n",
      "codes_bdlisa:string,\n",
      "bss_id:string,\n",
      "altitude_station:float64,\n",
      "nb_mesures_piezo:int64,\n",
      "code_departement:int64,\n",
      "nom_departement:string,\n",
      "libelle_pe:string,\n",
      "profondeur_investigation:float64,\n",
      "codes_masse_eau_edl:string,\n",
      "noms_masse_eau_edl:string,\n",
      "date_maj:string,\n",
      "date_mesure:string,\n",
      "timestamp_mesure:int64,\n",
      "niveau_nappe_eau:float64,\n",
      "mode_obtention:string,\n",
      "statut:string,\n",
      "qualification:string,\n",
      "code_continuite:float64,\n",
      "nom_continuite:string,\n",
      "code_producteur:int64,\n",
      "nom_producteur:string,\n",
      "code_nature_mesure:string,\n",
      "nom_nature_mesure:string,\n",
      "profondeur_nappe:float64,\n",
      "indicateur_piezometrique_standardise:float64,\n",
      "libelle_indicateur_piezometrique_standardise:string,\n",
      "urn_bss:string,\n",
      "urns_bdlisa:string,\n",
      "urns_masse_eau_edl:string,\n"
     ]
    }
   ],
   "source": [
    "for c in df_infos_stations_et_chroniques.columns:\n",
    "    dtype = df_infos_stations_et_chroniques[c].dtype.name.replace('object', 'string')\n",
    "    print(f\"{c}:{dtype}\", end=',\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
