{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8751f6f8-6259-47f5-8f2f-b68f0754bcde",
   "metadata": {},
   "source": [
    "### J'importe mes bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee39a8d-1c7e-4dc8-9119-5bd863063318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03668374-dbc7-4203-bb0f-b38a0b1376de",
   "metadata": {},
   "source": [
    "### Je creer ma session PySpark en précisant que j'utilise un seul Worker (Puisque je travail en local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa12508-5048-4bb2-93d1-fdd6c07ce102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def creerSession():\n",
    "    ''' Cette fonction permet de creer une session spark si elle n'existe pas déjà '''\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"Traitement InfoClimat\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0568c1-46d1-4515-b012-f04f1676ff48",
   "metadata": {},
   "source": [
    "### Je lis mon fichier CSV dans Pyspark\n",
    "\n",
    "Je précise qu'il n'y a pas de header et pas de schema de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c392c61f-484b-4858-90bf-cde916987e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lectureCSVSansHeader(nom_csv,spark):\n",
    "    ''' Cette fonction lit un fichier CSV et le charge sur spark \n",
    "    @param quoi ? Type ?\n",
    "    @return quoi ? Type ?\n",
    "    @Except quoi ?\n",
    "    '''\n",
    "    mes_donnees = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"false\").option(\"inferSchema\", \"false\")\\\n",
    "        .load(\"Data_brut/\"+nom_csv)\n",
    "    \n",
    "    return mes_donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f3d91-24f3-4324-898f-822e656e3222",
   "metadata": {},
   "source": [
    "### Je récupère les ligne avec Les villes et leur code associé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c7f40-1a74-4e0a-a04e-c35bbbade57b",
   "metadata": {},
   "source": [
    "Je veux connaitre le nombre de villes dans mon fichier, pour cela je compte les ligne avec un # dedans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65146812-5f9e-42ca-8084-5d5f7d613d01",
   "metadata": {
    "tags": []
   },
   "source": [
    "Je veux connaitre le nombre de ville dans mon fichier. Pour cela je comptre le nombre de lignes et je retire 3.\n",
    "\n",
    "* Une ligne avec METADATA\n",
    "* Une ligne avec la source\n",
    "* Une ligne avec la Licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30a51a8-c7e5-410d-a725-7054a0dbeafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recupere_lignes_inutiles(table_spark):\n",
    "    ''' Cette fonction permet de recupere les lignes inutiles et de récuperer les lignes avec le nom des villes '''\n",
    "    \n",
    "    #Je requete toutes les lignes avec un # devant, qui sont les lignes avec un # devant\n",
    "    lignes_diese = table_spark.select(\"_c0\")\\\n",
    "                    .filter(col(\"_c0\").contains(\"#\"))\n",
    "    \n",
    "    #J'extrait les lignes dans une variable\n",
    "    liste_lignes_diese = lignes_diese.collect()\n",
    "    \n",
    "    #Je compte le nombre de ville dans mon fichier\n",
    "    nombre_de_villes = lignes_diese.count() - 3\n",
    "    \n",
    "    return nombre_de_villes, liste_lignes_diese\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "508a22c1-81e0-4a3a-9c55-9a27ad535471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recuperer_codes_ville(liste_lignes_dieses, nombre_de_villes):\n",
    "    ''' Cette fontcion permet d'extraire les noms des villes et leur code et les stocker dans une liste associée, elle demande en entrée les lignes dièse et le nombre de villes '''\n",
    "    \n",
    "    # J'initialise ma liste vide\n",
    "    liste_ville = []\n",
    "    liste_code_et_ville=[]\n",
    "    \n",
    "    #Je fais une liste à partir de la ligne indice 1 et pour les lignes avec un nom de ville\n",
    "    for ligne in liste_lignes_dieses[1:nombre_de_villes+1]:\n",
    "        #Je cast mes lignes en str\n",
    "        ligne = str(ligne)\n",
    "        # Je retire la partie avant le #\n",
    "        ligne_split = ligne.split(\"# \")\n",
    "        # Je retire les deux derniers caractères de ma chaine de caractère ( correspond à : ') )\n",
    "        # Sur l'element indice 1 de mon split, je récupère du début jusqu'au deux derniers caractères\n",
    "        code_et_ville = ligne_split[1][:-2]\n",
    "        #Je sépare le code de nom de la ville. Je creer une liste avec le code et le nom de la ville\n",
    "        code_et_ville = code_et_ville.split(\":\")\n",
    "        #J'extrait le nom de ma ville dans une variable, je supprime l'espasce à l'avant du nom de la ville.\n",
    "        nom_de_ville = str(code_et_ville[1]).strip()\n",
    "        #J'atoute ma liste code_et_ville à ma liste de codes et villes\n",
    "        liste_code_et_ville.append(code_et_ville)\n",
    "    \n",
    "    return liste_code_et_ville"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35eda8-623b-4dca-87f1-b7a8f9f178ed",
   "metadata": {},
   "source": [
    "Avec une boucle for, je viens stocker les lignes avec le nom des ville et leur code dans une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b1cdb7-2ed3-4a61-8218-d6a8c3ee9bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listeVillesToDF(listeVilles,spark):\n",
    "    columns = [\"code\",\"ville\"]\n",
    "    mon_dataframe = spark.createDataFrame(data = listeVilles, schema = columns)\n",
    "    return mon_dataframe\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50551227-5671-4ec1-94db-5795e619fb6b",
   "metadata": {},
   "source": [
    "Je stocke mes codes et mes villes dans un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee0e84c-54d4-4518-867a-ca2326b5ecab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def villesdictionnaire(liste_villes_code, nombre_de_villes):\n",
    "    ''' Cette fonction transforme ma liste de ville en dictionnaire '''\n",
    "    villes = {liste_villes_code[i][0]:liste_villes_code[i][1] for i in range(nombre_de_villes)}\n",
    "    return villes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb31415-373d-45a5-91df-f9c6e90ef0e5",
   "metadata": {},
   "source": [
    "### Je supprime les lignes qui ne m'interesse pas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fdb41-6f3a-4ef1-8cb4-f11771d6e3fe",
   "metadata": {},
   "source": [
    "J'applique un filtre sur mes données pour retirer les lignes qui ne m'interesse pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f810e3-d76f-4c5e-9071-fb22a15cb881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tableSansInfo(table_spark):\n",
    "    \"\"\" Cette fonction selectionne la table spark sans les lignes contenant des informations \"\"\"\n",
    "\n",
    "    table_sans_info = table_spark.select(\"_c0\")\\\n",
    "            .filter(~col(\"_c0\").contains(\"#\") & ~col(\"_c0\").contains(\"degC\"))\n",
    "    \n",
    "    return table_sans_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5027681f-d543-47ce-ae25-aea23c26bcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exportCSV_uneColonne(table_spark):\n",
    "    \"\"\" Cette fonction export une table en csv \"\"\"\n",
    "    table_spark.write.csv(\"./fichierTemporaire.csv\", header = False, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29dae705-50d2-40c4-aea1-7d9bfa339c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lectureFichierTemporaire(nom_csv):\n",
    "    \"\"\" Cette fonction permet de lire un csv avec des header \"\"\"\n",
    "    donnees = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \";\")\\\n",
    "        .load(nom_csv+\".csv\")\n",
    "    return donnees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7725f81-2374-430d-9251-d7c777a7bb61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lectureCSVavecHeader(spark):\n",
    "    ''' Cette fonction lit un fichier CSV et le charge sur spark \n",
    "    @param quoi ? Type ?\n",
    "    @return quoi ? Type ?\n",
    "    @Except quoi ?\n",
    "    '''\n",
    "    mes_donnees = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "        .load(\"fichierTemporaire.csv\")\n",
    "    \n",
    "    return mes_donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "633e0c1e-ef1f-475c-8017-552d2a222a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerCodeVille(table_spark,liste_code):\n",
    "    \"\"\" Cette fonction remplace les codes présents en première colonne, par le nom des villes \"\"\"\n",
    "    nouvelle_table = table_spark.withColumn(\"Ville\",\\\n",
    "                                            when(col(\"station_id\").isin(liste_code.keys()),\\\n",
    "                                            remplacements[col(\"nom_colonne\")]) \\\n",
    "                                            .otherwise(col(\"nom_colonne\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa4e1cc-1e51-4d1a-8b66-279015e9871c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exportCSV_propre(table_spark):\n",
    "    \"\"\" Cette fonction export une table en csv \"\"\"\n",
    "    table_spark.write.csv(\"./infoclimat.csv\", header = True, mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c77c336-a5fd-4702-91ae-017a7dcf4d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exportCodesVille(table_spark):\n",
    "    \"\"\" Cette fonction export une table en csv \"\"\"\n",
    "    table_spark.write.csv(\"./codesVille.csv\", header = True, mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208494b9-fccf-41c6-81d2-db88175f0275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def testConnexion(reponse):\n",
    "    \n",
    "#     if reponse.status_code == 200:\n",
    "#         print(\"Code :{}, la connexion api est établie\".format(reponse.status_code))\n",
    "#     else:\n",
    "#         print(\"Code:{}, la connxeion api n'est pas établie\".format(reponse.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a606075d-92c2-4c88-b4f7-03ee84ff4fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def requeteAPI(code,date_debut,date_fin,token):\n",
    "#     '''\n",
    "#     Cette fonction fait une requete API sur la plateforme infoclimat\n",
    "#     Elle execute egalement la fonction testConnexion pour vérifier si la requete est réussie.\n",
    "    \n",
    "#     @param : code: str, date_debut : str, date_fin : str\n",
    "#     @retrun : contenu de la page\n",
    "#     '''\n",
    "#     URL=\"https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=\"+code+\"&start=\"+date_debut+\"&end=\"+date_fin+\"&token=\"+token\n",
    "    \n",
    "#     reponse = requests.get(URL)\n",
    "#     testConnexion(reponse)\n",
    "    \n",
    "#     return reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd20991-9762-4a80-878e-f7d38403515e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def ecritureCSV(nomFichier,reponse):\n",
    "#     with open(\"./Data_brut/\"+nomFichier,'w',newline='') as fichier:\n",
    "#         writer = csv.writer(fichier,delimiter=\" \")\n",
    "#         writer.writerow(reponse.text.splitlines(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b23262d4-e758-47f8-b242-6d5e54289f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    spark = creerSession()\n",
    "\n",
    "    donnees_brute = lectureCSVSansHeader(\"ceciEstUnTest.csv\",spark)\n",
    "\n",
    "    nombreVille, listeLigneInutiles = recupere_lignes_inutiles(donnees_brute)\n",
    "\n",
    "    codesVille = recuperer_codes_ville(listeLigneInutiles, nombreVille)\n",
    "    \n",
    "    codesVille_df = listeVillesToDF(codesVille,spark)\n",
    "    \n",
    "    exportCodesVille(codesVille_df)\n",
    "\n",
    "    lignesUtiles = tableSansInfo(donnees_brute)\n",
    "\n",
    "    exportCSV_uneColonne(lignesUtiles)\n",
    "\n",
    "    tablePropre = lectureCSVavecHeader(spark)\n",
    "\n",
    "    exportCSV_propre(tablePropre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d78ebb23-562f-49f3-93fd-19d8e10e244a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = \"000QW\"\n",
    "date_debut =\"2020-01-01\"\n",
    "date_fin = \"2020-12-31\"\n",
    "token = \"Emp8A4J9Pk587RT3M5SwlhQ4jk3VtHVt0Qlq4XritihpvshdM7BVg\"\n",
    "nomFichier = code+\"_\"+date_debut+\"_\"+date_fin+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90098595-2f62-4299-b87d-193d7741280d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378b3cd-78b2-41fa-939f-80edcae7551f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pour supprimer un dossier\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# shutil.rmtree('infoclimat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
