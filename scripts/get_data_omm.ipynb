{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import os\n",
    "import io\n",
    "from requests import get  # to retrieve files from web\n",
    "from dotenv import load_dotenv  # variables in .env\n",
    "import gzip  # unzip retrived files\n",
    "from datetime import datetime  # to get actual year and month\n",
    "import logging # log files\n",
    "import pandas as pd\n",
    "import random  # to generate random user-agent\n",
    "from lxml import etree # check README.md to solve install problem on Linux/macOS\n",
    "\n",
    "# init log format\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s , %(levelname)-8s , %(message)s\",\n",
    "    filename=\"logging_omm.log\",\n",
    "    datefmt=\"%Y-%m-%d , %H:%M:%S\",\n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stored_variables_in_env_file(VARENV:str):\n",
    "    \"\"\"load variables from .env file\n",
    "\n",
    "    Arguments:\n",
    "        VARENV -- searched env variable\n",
    "\n",
    "    Returns:\n",
    "        VARENV -- value for env variable\n",
    "    \"\"\"    \n",
    "    load_dotenv()\n",
    "    return os.getenv(VARENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_output_a_two_digit_month(month_value):\n",
    "    \"\"\"check if 'month' value is a 2 digit value\n",
    "\n",
    "    Arguments:\n",
    "        month_value -- current month value\n",
    "\n",
    "    Returns:\n",
    "        2 digits values\n",
    "    \"\"\"    \n",
    "    if len(str(month_value)) == 1:\n",
    "        month_value = f\"0{month_value}\"\n",
    "    else:\n",
    "        pass\n",
    "    return month_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_omm_file_url(url_to_complete,year_to_add,month_to_add):\n",
    "    \"\"\"compose the current url : https://donneespubliques.meteofrance.fr/donnees_libres/Txt/Synop/Archive/synop.<year><month>.csv.gz\n",
    "    \n",
    "    Arguments :\n",
    "        url_to_complete -- init_url\n",
    "        year_to_add -- targeted year\n",
    "        month_to_add -- targeted month\n",
    "    \n",
    "    Return :\n",
    "        completed_url -- recomposed url\n",
    "    \"\"\"\n",
    "    completed_url = f\"{url_to_complete}synop.{year_to_add}{check_and_output_a_two_digit_month(month_to_add)}.csv.gz\"\n",
    "    return completed_url\n",
    "\n",
    "def create_omm_filename(url_to_complete,year_to_add,month_to_add):\n",
    "    \"\"\"compose the current url : https://donneespubliques.meteofrance.fr/donnees_libres/Txt/Synop/Archive/synop.<year><month>.csv.gz\n",
    "\n",
    "    Arguments :\n",
    "        url_to_complete -- init_url\n",
    "        year_to_add -- targeted year\n",
    "        month_to_add -- targeted month\n",
    "\n",
    "    Return :\n",
    "        completed_file -- recomposed filename\n",
    "    \"\"\"\n",
    "    completed_filename = f\"synop.{year_to_add}{check_and_output_a_two_digit_month(month_to_add)}.csv\"\n",
    "    return completed_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(url_to_get,recomposed_filename):\n",
    "    \"\"\"retrieve a specific file from an url\n",
    "\n",
    "    Arguments :\n",
    "        url_to_get -- path to the file\n",
    "        recomposed_filename -- targeted file\n",
    "\n",
    "    Return :\n",
    "        website_response.content -- searched file\n",
    "    \"\"\"\n",
    "    website_response = get(url_to_get, allow_redirects=True)\n",
    "    if website_response.status_code == 200:\n",
    "        logging.info(f\"Successful Request with status code:, {website_response.status_code}\")\n",
    "    else:\n",
    "        logging.error(f\"Request failed for file {recomposed_filename} with status code:, {website_response.status_code}\")\n",
    "    return website_response.content\n",
    "\n",
    "def record_file(recomposed_filename,wished_extension,website_response):\n",
    "    os.makedirs(os.path.dirname(f\"data/{recomposed_filename}.{wished_extension}\"), exist_ok=True)\n",
    "    open(f\"data/{recomposed_filename}.{wished_extension}\", 'wb').write(website_response)\n",
    "\n",
    "def gunzip_file(__file__):\n",
    "    with open(f\"data/{__file__}.gz\", 'rb') as from_gz, open(f\"data/{__file__}\", 'w', encoding='utf8') as to_csv:\n",
    "        decompress_the_file = gzip.decompress(from_gz.read()).decode('utf-8')\n",
    "        to_csv.write(decompress_the_file)\n",
    "    os.remove(f\"data/{__file__}.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_as_dataframe(__file__):\n",
    "    temp = pd.read_csv(f\"data/{__file__}\", sep=\";\", header=0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(__file__):\n",
    "    temp = convert_csv_as_dataframe(__file__)\n",
    "    # make a copy of the dataframe with important columns to remove Pandas warning\n",
    "    df = temp[[\"numer_sta\",\"t\",\"td\",\"u\",\"date\"]].copy()\n",
    "    df[\"date_\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d%H%M%S\")\n",
    "    # create a 'date' column\n",
    "    df['date'] = df['date_'].dt.date\n",
    "    # create an 'hour' column\n",
    "    df['heure'] = df['date_'].dt.strftime('%H:%M')\n",
    "    # Drop the original timestamp column\n",
    "    df = df.drop('date_', axis=1)\n",
    "    df = df.rename({\"numer_sta\":\"ID\"},axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_user_agent_list() -> list:\n",
    "    \"\"\"generate a random user-agent list based on the most used user-agent\n",
    "\n",
    "    Parameters :\n",
    "        url_user_agent : url to retrieve the list\n",
    "    Returns:\n",
    "        user_agents : list\n",
    "    \"\"\"\n",
    "    url_user_agent = (\n",
    "        \"https://www.useragents.me/#most-common-desktop-useragents-json-csv\"\n",
    "    )\n",
    "\n",
    "    # Fetch the website content\n",
    "    response = get(url_user_agent)\n",
    "    if response.status_code != 200:\n",
    "        logging.error(\"Failed to fetch user agent list\")\n",
    "        pass\n",
    "\n",
    "    # Parse the HTML content\n",
    "    html = etree.HTML(response.text)\n",
    "\n",
    "    # Extract user agent strings using XPath\n",
    "    user_agents = html.xpath(\n",
    "        '//*[@id=\"most-common-desktop-useragents-json-csv\"]/div[1]/textarea/text()'\n",
    "    )\n",
    "    if not user_agents:\n",
    "        logging.error(\"Failed to extract user agent list\")\n",
    "        pass\n",
    "\n",
    "    # Parse the JSON data\n",
    "    try:\n",
    "        user_agents = eval(user_agents[0])\n",
    "    except:\n",
    "        logging.warning(\"Failed to parse user agent list\")\n",
    "        pass\n",
    "\n",
    "    return user_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_user_agent() -> dict:\n",
    "    \"\"\"select a random user-agent from the list\n",
    "\n",
    "    Returns:\n",
    "        random_user_agent : dict\n",
    "    \"\"\"\n",
    "    random_user_agent = {\"user-agent\": random.choice(generate_random_user_agent_list())[\"ua\"]}\n",
    "    return random_user_agent\n",
    "\n",
    "def retrieve_data_txt(url_station,file_station) -> dict:\n",
    "    \"\"\"Retrieve JSON datas from the URL\n",
    "\n",
    "    Parameters:\n",
    "    url_to_get: previously generated URL where to get datas\n",
    "\n",
    "    Returns:\n",
    "    data_json: dict\n",
    "    \"\"\"\n",
    "    user_agent = random_user_agent()\n",
    "    website_response = get(f\"{url_station}{file_station}\", headers=user_agent)\n",
    "    if website_response.status_code == 200:\n",
    "        data_txt = website_response.content\n",
    "    # Process the JSON data as needed\n",
    "    else:\n",
    "        logging.error(\n",
    "            f\"Request failed with status code:\", {website_response.status_code}\n",
    "        )\n",
    "    return data_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_the_job(target_url,current_loop_year,current_loop_month,url_station,file_station):\n",
    "    __url__ = create_omm_file_url(target_url,current_loop_year,current_loop_month)\n",
    "    __file__ = create_omm_filename(target_url,current_loop_year,current_loop_month)\n",
    "    record_file(__file__,\"gz\",get_file(__url__,__file__))\n",
    "    gunzip_file(__file__)\n",
    "    omm_data_loop=clean_data(__file__)\n",
    "    user_agents_list = generate_random_user_agent_list()\n",
    "    liste_station__ =retrieve_data_txt(url_station,file_station)\n",
    "    liste_of_station = pd.read_csv(io.StringIO(liste_station__.decode('utf-8')),sep=\";\")\n",
    "    final = pd.merge(omm_data_loop, liste_of_station, on=\"ID\")\n",
    "    try :\n",
    "        final.to_csv(f\"data/omm/{__file__}\",index = False)\n",
    "        logging.info(f\"Successfully record data : {current_loop_year}  {check_and_output_a_two_digit_month(current_loop_month)}\")\n",
    "    except:\n",
    "        logging.error(f\"Failed to record data : {current_loop_year}  {check_and_output_a_two_digit_month(current_loop_month)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # get the current date to retrieve from the initial file to the latest one\n",
    "    current_datetime = datetime.now()\n",
    "    year_loop_end = current_datetime.year\n",
    "    month_loop_end = current_datetime.month\n",
    "    #  dictionnary of stations\n",
    "    url_station = load_stored_variables_in_env_file(\"STATION_URL\")\n",
    "    file_station = load_stored_variables_in_env_file(\"STATION_FILE\")\n",
    "    # load variables from .env\n",
    "    year_loop_start = int(load_stored_variables_in_env_file(\"YEAR_LOOP_START\"))\n",
    "    month_loop_start = int(load_stored_variables_in_env_file(\"MONTH_LOOP_START\"))\n",
    "    target_url = load_stored_variables_in_env_file(\"URL\")\n",
    "\n",
    "    for current_loop_year in range(year_loop_start,year_loop_end+1):\n",
    "        for current_loop_month in range(month_loop_start,12+1):\n",
    "            make_the_job(target_url,current_loop_year,current_loop_month,url_station,file_station)\n",
    "            if (current_loop_year == year_loop_end) and (current_loop_month == month_loop_end):\n",
    "                logging.info(f\"Task ended from {year_loop_start}{month_loop_start}\")\n",
    "                break\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
